
//[[clause-reference]]
== ARD to Decision Ready Indicator (DRI)

A decision Ready Indicator (DRI) is information and knowledge that is in such a format that it provides specific support for actions and decisions that have to be made. These indicators are pre-determined, using a set recipe which pulls together one or more ARDs to create an indicator of action and/or decision. DRIs hold significant importance as they serve as benchmarks or criteria to determine when a decision-making process is adequately prepared and can proceed efficiently. Their importance lies in several aspects. Firstly, DRIs facilitate efficient decision-making by signaling that all necessary information, analysis, and resources are available, minimizing delays and preventing hasty or uninformed decisions. Secondly, they ensure quality assurance by setting standards for the decision-making process, ensuring thorough consideration of relevant factors, accurate analysis, and reliable information. DRIs also promote accountability and transparency by defining expectations and providing a framework for evaluation, enabling stakeholders to understand the reasoning behind decisions and hold decision-makers accountable. Additionally, DRIs aid in effective resource allocation by identifying the point at which resources can be allocated, preventing wastage on underprepared decisions. They also assist in managing risks associated with decision-making by encouraging thorough analysis and consideration of potential risks. Furthermore, DRIs promote consistency and standardization, reducing subjectivity and increasing fairness across different decisions. In summary, DRIs play a crucial role in ensuring well-prepared, informed, and accountable decision-making processes, enhancing efficiency, quality, transparency, and resource management.

Analyze Ready Data (ARD), data that have been processed to a minimum set of requirements and organized into a form that allows immediate analysis with a minimum of additional user effort and interoperability both through time and with other datasets, form the building blocks for DRIs. The transition from ARDs to DRIs encompasses a series of steps designed to extract meaningful insights and facilitate informed decision-making. It commences with the collection and preparation of data, where relevant information is gathered from diverse sources and formatted appropriately for analysis. This involves data cleaning, standardization, and transformation to ensure consistency and reliability. Following data preparation, the integration stage merges multiple data sources, aligning them based on common variables or identifiers, thereby creating a comprehensive dataset.

Subsequently, data exploration and analysis techniques are employed to delve into the dataset's intricacies. Through statistical analysis, data visualization, and data mining, analysts uncover patterns, relationships, and trends that enable a deeper understanding of the underlying information. Feature engineering plays a crucial role in enhancing the analytical model's performance. By selecting pertinent features, transforming existing variables, handling missing data, and encoding categorical variables, analysts optimize the model's ability to extract insights from the data.

Once the data is prepared and features are engineered, model development ensues. Depending on the nature of the problem and the data at hand, analysts choose appropriate algorithms, such as regression, classification, clustering, or machine learning, to build predictive or analytical models. These models are then trained using a portion of the data, often referred to as the training set. Validation is performed using a separate portion of the data, the validation set, to assess the model's performance and fine-tune it for optimal results.

With the validated model in place, the focus shifts to generating Decision Ready Indicators (DRIs). These indicators are specific metrics, scores, or predictions derived from the model's outputs, providing actionable insights relevant to the decision-making process. The DRIs serve as valuable tools that support decision-makers in interpreting the analyzed data and guide them in making well-informed choices.

The generated DRIs become pivotal components in the decision-making process. Decision-makers leverage these indicators to assess different scenarios, evaluate risks, and identify opportunities. By incorporating the insights gained from the analyzed data and model outputs, decision-makers can make more informed and data-driven decisions, enhancing their ability to achieve desired outcomes.

It is worth noting that while the outlined steps provide a general framework, the specific implementation of the process may vary based on the unique context, data characteristics, and analytical techniques employed. Nonetheless, the overarching objective remains constant: to transform Analyze Ready Data into Decision Ready Indicators that facilitate effective decision-making. Below we provide examples on what DRIs can be developed in relation to Climate Resilience.


=== Wildfire hazard component

To develop its component, Intact migrated its previous proprietary wildfire hazard model to a private on-premise data science environment. For key inputs to the model, external connections to several open data repositories were established. To facilitate these access tests, several public open source datasets, such as climate model outputs, Earth observations, weather and geospatial, were vetted by the appropriate cybersecurity boards. The tests also informed experts of changes in platforms offerings, of new data products specifications, applicable licenses, and of current authoritative scientific references.

[[Figure3_Intact]]
.Two samples of IFC’s current national wildfire hazard map
image::Figure3_Intact.png[Figure3_Intact]

The table below shows the datasets accessed by Intact during the pilot.

===== Technical Interoperability Experiments (TIE) Table
[%unnumbered]
[width="90%",options="header"]
|====================
|Dataset |Source |URL |Notes
|National Fire Database fire polygon data | NRCan | https://cwfis.cfs.nrcan.gc.ca/datamart/download/nfdbpoly | Unable to establish SSL connection into private network
|Fire Weather Index and its components	| NRCan | https://cwfis.cfs.nrcan.gc.ca/downloads/fwi_obs/ | Unable to establish SSL connection into private network
|Forest Fuels |	NRCan | ftp://ftp.nofc.cfs.nrcan.gc.ca/pub/fire/cwfis/data/fuels/ |
|Vegetation concentration and mass | NRCan | http://tree.pfc.forestry.ca/ | 503 Service Unavailable from private network
|Daily reanalysis composites | NOAA | https://psl.noaa.gov/data/composites/day/ |
|Monthly reanalysis composites | NOAA | https://psl.noaa.gov/cgi-bin/data/composites/printpage.pl |
|Global temperature anomalies/trends | NASA | https://data.giss.nasa.gov/gistemp/maps/ |
|Elevation at 30 meters | NASA | https://lpdaac.usgs.gov/products/nasadem_hgtv001/ |
|Canadian Drought Monitor | AAFC | https://agriculture.canada.ca/atlas/data_donnees/canadianDroughtMonitor/data_donnees/shp/ |
|Canadian Lightning Detection Network |	NRCan | ftp://ftp.nofc.cfs.nrcan.gc.ca/pub/fire/CLDN/ | Connection timed out, can’t find alternate source
|Topography | USGS | https://topotools.cr.usgs.gov/gmted_viewer/viewer.htm | Interactive map, not layers
|Road segments | NRCan | ftp://ftp.nofc.cfs.nrcan.gc.ca/pub/fire/cwfis/data/base_data | Connection timed out, can’t find alternate source
|Population of the world | Columbia U. | https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density/data-download |
|CanVec Manmade Structures| NRCan | http://ftp.geogratis.gc.ca/pub/nrcan_rncan/vector/canvec/shp/ManMade/ | 503 Service Unavailable from private network |

|====================

Below is a summarized list of the key datasets required to produce or update a wildfire hazard map.

•	National fire database polygon data

•	Fire Weather Index (FWI) daily maps

•	Land cover maps

•	Drought conditions

•	Digital Elevation Model (DEM)

•	Population density

•	Fuel and vegetation data

Intact’s wildfire hazard map is developed exclusively for internal use. Aside from intellectual property terms, it is meant to be deployed in highly secured data environments, and as such it cannot readily interact with other components of the pilot at this point of time. The intent is to develop geospatial infrastructures and legal terms that would allow a closer collaboration with pilot’s participants.

Very early in the project, Intact also developed an H3 synthetic exposure dataset (see next figure) composed of 14M points spread out across the country in a statically representative pattern. The purpose of this dataset was to facilitate visualization and analysis of the exposure. It was also supposed to allow pilot participants to have a common exposure reference on which to develop decision-ready use cases for insurance, thus advancing towards standardization. Unfortunately, time constraints prevented update and sharing of this dataset.

[[Figure4_Intact]]
.IFC’s exposure synthetic dataset, with Montreal – Ottawa corridor on the left, and close-up of Montreal on the right. Color scale represent relative risk density in each cell, while points are representative individual risks
image::Figure4_Intact.png[Figure4_Intact]

// === Pelagis

=== The Blue Economy
Pelagis' participation in the Climate Resilience pilot focuses on enhancing our view of a global oceans observation system by combining real-world ground observations with analysis ready datasets. Monitoring aspects of our oceans through both a temporal and spatial continuum while providing traceability through the observations process allows stakeholders to better understand the stressors affecting the health of our oceans and investigate opportunities to mitigate the longer term implications related to climate change.

The approach to address the needs for a sustainable ocean economy is to make Marine Spatial Planning a core foundation on which to build out vertical applications. Pelagis' platform is based on a federated information model represented as a unified social graph. This provides a decentralized approach towards designing various data streams each represented by their well-known and/or standardized model. To date, service layers based on the OGC standards for Feature, Observations & Measurements, and Sensors APIs have been developed and extended for adoption within the marine domain model. Previous work provides for data discovery and processing of features based on the IHO S-100 standard (Marine Protected Areas, Marine Traffic Management, …); NOAA open data pipelines for major weather events (Hurricane Tracking, Ocean Drifters, Saildrones …); as well as connected observation systems as provided by IOOS and its Canadian variant, CIOOS.


==== From Raw Data to ARD and Decision Ready Indicators
The United Nations Framework Convention on Climate Change (UNFCCC) is supported through a number of organizations providing key observation data related to climate change.  Of primary interest to this project scenario is the Global Climate Observing System (GCOS) and Global Ocean Observing System (GOOS), and the Joint Working Group on Climate (WG Climate) of the Committee on Earth Observation Satellites (CEOS).  In-situ data sources are provided through a number of program initiatives sponsored through NOAA and provide key indicators for climate change that cannot be directly inferred from raw satellite information.

GCOS defines 54 Essential Climate Variables of which 18 ECVs apply to the oceans domain.  Of these, only 6 ECVs may be inferred from satellite based earth observations while the remainder must be inferred through in-situ site observations and/or sampling programs.

The following table identifies the ocean-specific ECVs and associated providers.

.Ocean-specific ECVs and associated providers
[cols="1,3, 2"]
|===
| Variable | Description | Source of Indicator

| Ocean Colour | Provides indictation of phytoplankton based on Ocean Colour Radiance (OCR) | ESA CEOS
| Carbon Dioxide Partial Pressure | Primary indicator of the exchange of CO~2~ at the ocean surface | NOAA
| Ocean Acidity | pH of ocean water as measured at varying depths and locations | NOAA PMEL
| Phytoplankton | Indicator of the health of the ecosystem associated with the food web and directly a result of increased CO~2~ and eutrophication | NOAA
| Sea Ice | Sea ice coverage associated with the ocean surface and a concern reflected in warming surface temperatures and sea level rise |
| Sea Level | Sea level global mean and variability leading to sea level rise |
| Sea State | Wave height, direction, wavelength as indicators of energy at the ocean surface |
| Sea-surface Salinity | The proportion of ocean water comprised of salt and indicator of mortality rates in shellfish |
| Sea-surface Temperature | Directly affects major weather patterns and ecosystems | ESA CEOS; NOAA Monitoring Stations; NOAA Saildrone program
| Surface Current | Transports heat, salt and passive tracers and has a large impact on seaborne commerce and fishing |
|===

As well, social and economic key indicators related to the area of interest are ingested to identify relationships between the immediate effects of climate change on the associated human activity.

.Social and economic key indicators
[cols="1,3, 2"]
|===
| Variable | Description | Source of Indicator

| AQ Landings | Annual yields associated with Aquaculture sites within a region of interest | MaineAQ
| GDP | Gross Domestic Product ($USD) associated with dependent human activities within the region of interest | US Census
| Employment | Number of individuals dependent on the targeted ecosystem | US Census
| Population | Number of people inhabiting the area of interest associated with the ecosystem | US Census
|===

==== Approach
Each ECV applicable to the use case is resolved as a service endpoint representing the area of interest, associated samplings and observations, and where possible inferred from earth observation datasets transformed as 'analysis ready'.
Earth observation datasets are sourced through the ESA GCOS service endpoint; Ocean related samplings and in-situ observations are sourced through NOAA; socio-economic data is sourced from various open data portals available through government agencies.

The project effort centers around 3 key challenges
* the ability to collect data relevant to Climate Resilience;
* the ability to apply the data in a coherent and standardized manner in which to draw out context;
* and the ability to impart insight to community members and stakeholders so as to identify, anticipate and mitigate the effects of climate change across both local and international boundaries.

Each of these activities aligns with the best practices and standards of the OGC and are used as input to the MarineDWG MSDI reference model.


[#img-pelagis-architecture]
.Architecture
image::pelagis.architecture(1).svg[Pelagis-architecture, ,align=center, width=600]

=== DRI: Heat Impact and Drought Impact Components

==== Heat Impact DRI Component

This component takes the climate scenario summary ARD results from the ARD component and analyzes them to derive estimated heat impacts over time, based on selected climate scenarios. Central to this is the identification of key heat impact indicators required by decision makers and the business rules needed to drive them. Process steps include data aggregation and statistical analysis of maximum temperature spikes, taking into account the cumulative impacts of multiple high temperature days. Heat exhaustion effects are likely dependent on duration of heat spells, in addition to high maximum temperatures on certain days.

[[SafeSoftware_6]]
.ARD Query: Monthly Max Temp Contours
image::SafeSoftware_6.png[SafeSoftware_6]

[[SafeSoftware_7]]
.ARD Query: Max Mean Monthly Temp > 25C
image::SafeSoftware_7.png[SafeSoftware_7]

[[SafeSoftware_8]]
.Town of Lytton - location where entire town was devastated by fire during the heat wave of July 2021 - same location highlighted in ARD query from heat risk query in previous figure
image::SafeSoftware_8.png[SafeSoftware_8]

==== Drought Impact DRI Component

This component takes the climate scenario summary ARD results from the ARD component and analyzes them to derive estimated drought risk impacts over time based on selected climate scenarios. It also feeds drought related environmental factors to other pilot DRI components for more refined drought risk analysis. For the purposes of this pilot, it was recognised that more complex indicators such as drought are likely driven by multiple environmental and physical factors. As such, our initial goal was to select and provide primary climate variable data that would be useful for deriving drought risks in combination with other inputs. Given that the primary input to drought models is precipitation, or lack thereof, we developed a data flow that extracted total precipitation per month and made this available both as a time series CSV and GeoJSON datasets, as well as OGC API features time series points. This climate scenario primary drought data was provided for the province of Manitoba and for Los Angelas. These two regions were chosen since we had pilot participants interested in each of these regions and in the case of Manitoba there is also a tie in to future work as this is an area of interest for the subsequent Disaster Pilot 2023.

For the LA use case, we worked with Laubwerk to provide them with climate change impact data that could help drive a drought impact that could affect their future landscape visualization model. The idea is that based on changes to climatic variables, certain areas may be more or less suited to different vegetation types, causing the distribution of vegetation to change over time. For more on their component, please refer to section 7: From Data To Visualization.

In the case of this visualization component, simply providing precipitation totals per month were not sufficient to drive the needs of their vegetation model. In this case we did not have an intermediate drought model to feed climate variables to. In the absence of a more comprehensive drought model, we decided to develop a proxy drought risk indicator by normalizing the difference between future precipitation and past.

Calculations were made using the difference between time series grids of projected precipitation and historical grids of mean precipitation per month. These precipitation deltas were then divided by the historical max - mean per month to derive a precipitation index. The goal was to provide a value between -1 and +1 where 1 = 100% of past mean precipitation for that month. Naturally this approach can generate values that exceed the range of -1 to 1 if the projected precipitation values exceed the historic max or min. The goal was not so much to predict future absolute precipitation values but rather generate an estimated for precipitation trends given the influence of climate change. For example, this approach can help answer the question - in 30 years for a given location, compare to historical norms, by what percentage do we expect precipitation to increase or decrease. Laubwerk can then take these results and decide what degree of drought stress will cause a specific vegetation species to die out for a particular location.

Interesting patterns emerged for the LA area that we ran this process on deltas between projected and historical precipitation. While summers are typically dry and winters are wet and prone to flash floods. Initial data exploration seemed to show an increase in drought patterns in the spring and fall. More analysis needs to be done to see if this is a general pattern or simply one that emerged from the climate scenario we ran. However, this  is the type of trend that local planners and managers may benefit from having the ability to explore once they have better access to climate model scenario outputs along with the ability to query and analyze them.

[[FME_Query_Workflow_LA_precip]]
.FME Query Workflow: Geopackage precipitation delta time series to GeoJSON points
image::FME_Query_Workflow_LA_precip.png[FME_Query_Workflow_LA_precip]]

[[FME_DroughtQuery1Params_LA]]
.FME Query Parameters:  Geopackage precipitation delta time series to GeoJSON points
image::FME_DroughtQuery1Params_LA.png[FME_DroughtQuery1Params_LA.png]]

[[FME_Result_DroughtQuery1_LA]]
.FME Data Inspector: precipitation delta result showing potential drought risk for areas and times with significantly less precipitation than past
image::FME_Result_DroughtQuery1_LA.png[FME_Result_DroughtQuery1_LA]]

This approach is only a start and just scratches the surface in terms of what is possible for future drought projection based on climate model scenario ECVs. The specific business rules used to assess drought risk are still under development. FME provides a flexible data and business rule modeling framework. This means that as indicators and drought threshold rules are refined, it's relatively straightforward to adjust the business rules in this component to refine our risk projections. Also, business rule parameters can be externalized as execution parameters so that end users can control key aspects of the scenario drought risk assessment without having to modify the published FME workflow. However one of the main goals of this pilot was not so much to produced highly refined forecast models for drought but rather to demonstrate the data value chain whereby raw climate model data cube outputs can feed a data pipeline that filters, refines, simplifies the data and ultimately can be used to drive indicators that help planners model visualize and understand the effects of climate change on the landscapes and environments within their communities.

To support future drought risk estimates for Manitoba, we also provided a precipitation forecast time series to Pixalytics as an input to their drought analytics and DRI component. Their component provides a much more sophisticated indicator of drought probability since in addition to precipitation it also takes into account soil moisture and vegetation. The goal was to extract precipitation totals per time step from the downscaled RCM - regional climate model ECV outputs for Manitoba based on CMIP5 (Coupled Model Intercomparison Project Phase 5) model results obtained from Environment Canada. For this use case the grids have a spatial resolution of roughly 10km and a temporal resolution a monthly time step. Pixalytics then ran their drought model based on these precipitation estimates in order to asses potential future drought risk in southern Manitoba. The data was provided to Pixalytics initially as a GeoJSON feed of 2d points derived from the data cube cells with precipitation totals per cell. We later also provided this same data feed as a OGC API Feature service.

For future phases of the climate or disaster pilots, it may be useful to explore additional approaches for both precipitation data analysis and combination with other related datasets and external models. It may be useful to segment cumulative rainfall below a certain threshold Pt within a certain time window (days, weeks or months), since cumulative rainfall over time will be crucial for computing water budgets by watershed or catch basin. To do this we would like to test the use of a higher resolution time step such as daily, to see if the increased resolution reveals patterns of interest that the coarser monthly time step does not. There are also other statistical RCM results that might be useful to make available (mean, min, max). Besides precipitation, climate models also generate soil moisture predictions which could used by this component to assess drought risk. This component would also benefit from integration with topography, DEMs and hydrology related data such as river networks, water bodies, aquifers and watershed boundaries. Therefore rather than just computing precipitation deltas at the cell level, it would likely be useful to sum precipitation by catch basin and compute future trends that may indicate potential drought or flood.

The specific business rules used to assess drought risk are still under development. FME provides a flexible data and business rule modeling framework. This means that as indicators and drought threshold rules are refined, it's relatively straightforward to adjust the business rules in this component to refine our risk projections. Also, business rule parameters can be externalized as execution parameters so that end users can control key aspects of the scenario drought risk assessment without having to modify the published FME workflow.

It should be stressed that the field of drought modelling is not new and there are many drought modelling tools available that are far more sophisticated than anything described above. As such, subsequent Climate and Disaster pilots should explore how future climate projections can  be funneled into these more mature climate models in an automated fashion to produce more refined estimates of projected drought risk. That said, we need to start somewhere, and it is hoped that this basic demonstration of the raw data to ARD to DRI value chain for drought can provide some insights into what type of indicators we may want to generate to help better understand future drought risks, and where we may want to improve on this process.
