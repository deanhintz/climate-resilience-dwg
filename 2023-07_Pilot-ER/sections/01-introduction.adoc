
== Introduction

The OGC Climate Resilience Pilot represents the first phase of multiple long term climate activities aiming to combine geospatial data, technologies, and other capabilities into valuable information for decision makers, scientists, policy makers, data providers, software developers, and service providers to assist in making valuable, informed decisions to improve climate action. 

=== The goal of the pilot 

The goal of this pilot was to enable decision makers (scientists, city managers, politicians, etc.) in taking the relevant actions to address climate change and make well informed decisions for climate change adaptation. Since no single organization has all the data needed to understand the consequences of climate change, this pilot shows how to use data from multiple organizations--available at different scales for large and small areas--in scientific processes, analytical models, and simulation environments. The aim was to demonstrate visualization and communication tools used to craft the message in the best way for any client. Many challenges can be met through resources that adhere to FAIR (Findable, Accessible, Interoperable, and Reusable) principles. The OGC Climate Resilience Pilot identifies, discusses, and develops these resources.

The goal was to help the location community develop more powerful visualization and communication tools to accurately address ongoing climate threats such as heat, drought, floods, and fires as well as supporting nationally determined targets for greenhouse gas emission reduction. Climate resilience is often considered the use case of our lifetime; the OGC community is uniquely positioned to accelerate solutions through collective problem solving with this initiative.

[[ValueChain]]
.Value chain from raw data to climate information
image::CCS_Pilot_Concept.png[ValueChain]

As illustrated, large sets of raw data from multiple sources require further processing in order to be used for analysis and climate change impact assessments. Applying data enhancement steps, such as bias adjustments, re-gridding, or calculation of climate indicators and essential variables creates “Decision Ready Indicators.” The spatial data infrastructures required for this integration should be designed with interoperable application packages following FAIR data principles. Heterogeneous data from multiple sources can be enhanced, adjusted, refined, or quality controlled to provide Science Services data products for Climate Resilience. The OGC Climate resilience pilot also illustrates the graphical exploration of the Decision Ready Indicators and effectively demonstrates how to design FAIR climate resilience information systems underpinning FAIR Climate Services. The OGC Pilot participants illustrate the necessary tools and the visualizations to address climate actions moving towards climate resilience.

The vision of the OGC Climate Resilience Community is to support efforts on climate actions, enable international partnerships (SDG 17), and move towards global interoperable open digital infrastructures providing climate resilience information on demand by users. This pilot contributes to establishing an OGC climate resilience concept store for the community where all appropriate climate information to build climate resilience information systems as open infrastructures can be found in one place, be it information about data services, tools, software, or handbooks, or a place to discuss experiences and needs. It covers all phases of Climate Resilience from initial hazards identification and mapping, vulnerability and risk analysis, options assessments, prioritization, and planning, to implementation planning and monitoring capabilities. These major challenges can only be met through the combined efforts of many OGC members across government, industry, and academia. 

=== Objectives

This Pilot set the stage for a series of follow up activities and focuses on use-case development, implementation, and exploration. It also answers the following questions.

- What use-cases can be realized with the data, services, analytical functions, and visualization capabilities currently available? Current data services include, for example, the Copernicus Services, including Climate Data Store (CDS) https://cds.climate.copernicus.eu/ and Atmosphere Data Store (ADS) https://ads.atmosphere.copernicus.eu/.

- How much effort is required to realize these use-cases?

- What is missing, or needs to be improved, in order to transfer the use-cases developed in the pilot to other areas?

The pilot had three objectives:

- to better understand what is currently possible with the available data and technology;

- to determine what additional data and technology need to be developed in the future to better meet the needs of the Climate Resilience Community; and

- to capture Best Practices and allow the Climate Community to copy and transform as many use-cases as possible to other locations or framework conditions.

=== Background

With growing local communities, an increase in climate-driven disasters, and an increasing risk of future natural hazards, the demand for National Resilience Frameworks and Climate Resilience Information Systems (CRISs) cannot be overstated. CRISs are enabling data-search, -fetch, -fusion, -processing, and -visualization enabling access, understanding, and use of federal data, facilitating integration of federal and state data with local data, and serving as local information hubs for climate resilience knowledge sharing.

CRISs already exist and are operational, such as the Copernicus Climate Change Service with the Climate Data Store. CRIS architectures can be further enhanced by providing scientific methods and visualization capabilities as climate application packages. Based on FAIR principles, these application packages enable the reusability of CRIS features and capabilities. Reusability is an essential component when goals, expertise, and resources are aligned from the national to the local level. Framework conditions differ across nations, but application packages enable as much reuse of existing Best Practices, tools, data, and services as possible.

Goals and objectives of decision makers vary at different scales. At the municipal level, leaders and citizens directly face climate-related hazards. Aspects thus come into focus, such as reducing vulnerability and risk, building resilience through local measures, or enhancing emergency response. At the state level, the municipal efforts can be coordinated and supported by providing funding and enacting relevant policies. The national, federal, and international levels provide funding, data, and international coordination to enable the best analyses and decisions at the lower scales.

.Schematic synergies within different climate and science services FAIR and open infrastructures
image::Interoperable_ScienceService.png[image]

Productivity and decision making are enhanced when climate application packages are exchangeable across countries, organizations, or administrative levels (see Figure 2). This OGC Climate Resilience Pilot is a contribution towards an open, multi-level infrastructure that integrates data spaces, open science, and local-to-international requirements and objectives. It contributes to the technology and governance stack that enables the integration of data including historical observations, real time sensing data, reanalyses, forecasts, and future projections. It addresses data-to-decision pipelines, data analyses, and representation, and bundles everything in climate resilience application packages. These application packages are complemented by Best Practices, guidelines, and cook-books that enable multi–stakeholder decision making for the good of society in a changing natural environment.

The OGC Innovation Program brings all of the various groups together: members of the stakeholder groups define use cases and requirements; the technologists and data providers experiment with new tools and data products in an agile development process; and the scientific community provides results in appropriate formats and enables open science by providing applications that can be parameterized and executed on demand.

.The OGC Climate Resilience DWG and Pilot brings the climate resilience community together with infrastructure providers, policy makers, commercial companies, and the scientific community
image::Climate_Resilience_Pilot_Interaction.png[]

This OGC Climate Resilience Pilot is part of the OGC Climate Community Collaborative Solution and Innovation process, an open community process that uses OGC as the governing body for collaborative activities among all members. A spiral approach is applied to connect technology enhancements, new data products, and scientific research with community needs and framework conditions at different scales. The spiral approach defines real world use cases, identifies gaps, produces new technology and data, and tests these against the real world use cases before entering the next iteration. Evaluation and validation cycles alternate and continuously define new work tasks. These tasks include documentation and toolbox descriptions on the consumer side, and data and service offerings, interoperability, and system architecture developments on the producer side. It is emphasized that research and development is not constrained to the data provider or infrastructure side. Many tasks need to be executed on the data consumer side in parallel and then merged with advancements on the provider side in regular intervals.

Good results have been achieved using OGC API standards in the past. For example, the remote operations on climate simulations (roocs) use OGC API Processes for subsetting data sets to reduce the data volume being transported. Other systems use OGC STAC for metadata and data handling or OGC Earth Observation Exploitation Platform Best Practices for the deployment of climate application packages into CRIS architectures. Still, data handling regarding higher complex climate impact assessments within FAIR and open infrastructures needs to be enhanced. There is no international recommendation or best practice on usage of existing API standards within individual CRISs. It is the goal of this pilot to contribute to the development of such a recommendation, respecting existing operational CRISs already in service.

.Schematic Architecture of a Climate Resilience Information System. By respecting FAIR principles for the climate application packages the architecture enables open infrastructures to produce and deliver information on demand of the users needs
image::FAIR_Data_Spaces.png[]

=== Technical Challenges

Realizing the delivery of Decision Ready Data on demand to achieve Climate Resilience involves a number of technical challenges that have already been identified by the community. A subset will be selected and embedded in use-cases that will be defined jointly by Pilot Sponsors and the OGC team. The goal is to ensure a clear value-enhancement pipeline as illustrated in Figure 1, above. This includes, among other elements, a baseline of standardized operators for data reduction and analytics. These need to fit into an overall workflow that provides translation services between upstream model data and downstream output - basically from raw data to analysis-ready data to decision-ready data. 

The following technical challenges have been identified and will be treated in the focus areas of the pilot.

- Big Data Challenge: Multiple obstacles still exist which create barriers for seamless information delivery starting from Data Discovery. The emergence of new data platforms, processing functionalities, and products means that data discovery remains a challenge. In addition to existing solutions based on established metadata profiles and catalog services, new technologies such as OGC’s Spatio-Temporal Asset Catalog (STAC) and open Web APIs such as OGC API Records will be explored. Furthermore, aspects of Data Access need to be solved where the new OGC API suite of Web APIs for data access, subsetting, and processing are currently utilized very successfully in several domains. Several code sprints have shown that server-side solutions can be realized within days and clients can interact very quickly with these server endpoints, radically reducing development time. A promising specialized candidate for climate data and non-climate data integration has been recently published in the form of the OGC API - Environmental Data Retrieval (EDR). But which additional APIs are needed for climate data? Is the current set of OGC APIs sufficiently qualified to support the data enhancement pipeline illustrated in Figure 1? If not, what modifications and extensions need to be made available? How do OGC APIs cooperate with existing technologies such as THREDDS and OPEnDAP? For challenges of data spaces, Data Cubes have recently been explored in the OGC Data Cube workshop. Ad hoc creation and embedded processing functions have been identified as essential ingredients for efficient data exploration and exchange. Is it possible to transfer these concepts to all stages of the processing pipeline? How can users scale both ways from local, ad hoc cubes to pan-continental cubes, and vice versa? How can cubes be extended as part of data fusion and data integration processes?

- Cross-Discipline Data Integration: Different disciplines such as Earth Observation, various social sciences, or climate modeling use different conceptual models in their data collection, production, and analytical processes. How can these different models be mapped? What patterns have been used to transform conceptual models to logical models and, eventually, physical models? The production of modern Decision-ready information requires the integration of several data sets, including census and demographics, further social science data, transportation infrastructure, hydrography, land use, topography and other data sets. This pilot cycle uses 'location' as the common denominator between these diverse data sets which works with several data providers and scientific disciplines. In terms of Data Exchange Formats, the challenge is to know what data formats need to be supported at the various interfaces of the processing pipeline. What is the minimum constellation of required formats to cover the majority of use cases? What role do container formats play? Data Provenance is also challenging on the technical level. Many archives include data from several production cycles, such as IPCC AR 5 and AR 6 models. In this context, long term support needs to be realized and full traceability from high level data products back to the original raw data. Especially in context of reliable data based policy, clear audit trails and accountability for the data to information evolution must be ensured.

- Application packages for processing pipelines: Machine Learning and Artificial Intelligence plays an increasing role in the context of data science and data integration. This focus area evaluates the applicability of machine learning models in the context of the value-enhancing processing pipeline. What information needs to be provided to describe machine learning models and corresponding training data sufficiently to ensure proper usage at various steps of the pipeline? Upcoming options to deploy ML/AI within processing APIs to enhance climate services are rising challenges, e.g., on how to initiate or ingest training models and the appropriate learning extensions for the production phase of ML/AI. Heterogeneity in data spaces can be bridged with Linked Data and Data Semantics. Proper and common use of shared semantics is essential to guarantee solid value-enhancement processes. At the same time, resolvable links to procedures, sampling and data process protocols, and used applications will ensure transparency and traceability of decisions and actions based on data products. What level is currently supported? What infrastructure is required to support shared semantics? What governance mechanisms need to be put in place?

=== Relevance to the Climate Resilience Domain Working Group

The Climate Resilience DWG will concern itself with technology and technology policy issues, focusing on geospatial information and technology interests as related to climate mitigation and adaptation, as well as the means by which those issues can be appropriately factored into the OGC standards development process.

The mission of the Climate Resilience DWG is to identify geospatial interoperability issues and challenges that impede climate action, then examine ways in which those challenges can be met through the application of existing OGC Standards, or through development of new geospatial interoperability standards under the auspices of OGC.

Activities to be undertaken by the Climate Resilience DWG include, but are not limited to:

* identify the OGC interface standards and encodings useful to apply FAIR concepts to climate change services platforms;
* liaise with other OGC Working Groups (WGs) to drive standards evolution;
* promote the use of the aforementioned standards with climate change service providers and policy makers addressing international regional and local needs;
* liaise with external groups working on technologies relevant to establishing ecosystems of EO Exploitation Platforms;
* liaise with external groups working on relevant technologies;
* publish OGC Technical Papers, Discussion Papers, or Best Practices on interoperable interfaces for climate change services; and
* provide software tool kits to facilitate the deployment of climate change services platforms.


=== Value Chain from raw data to Information

During this pilot, participants have worked on a number of workflows and architectures focusing on several use cases of floods, droughts, heatwaves, and fires. It required the use of Climate Resilience Information Systems where interoperability played a vital role in producing climate information by enabling seamless integration and exchange of information between data, models, and various components. 

The value chain from raw data to climate information (<<ValueChain>>) can be clustered in sections according to the value quality. This value chain, often also compared to a conveyor belt, can be designed with different component workflows which are developed, analyzed, and described in this pilot. The order of the chapters of the document reflects value chain organizing and processing starting from *<<Chapter_Raw_data_datacubes,style=basic%>>* (Chapter <<Chapter_Raw_data_datacubes,droploc%>>). The following Chapter <<Chapter_ARD,droploc%>> describes the data refinement from *<<Chapter_ARD,style=basic%>>*. Various data pipelines are considered and evaluated on how best to move raw data, first to data cubes for efficient handling, and then how to process them to ARD, or derive the ARD directly from the raw data. This guides the discussion on the standardization of Data Cubes and ARD. Subsequently, Chapter <<Chapter_DRI,droploc%>>, illustrates how to transform *<<Chapter_DRI,style=basic%>>* by including an example set of climate indices. The pilot also demonstrates the value added of high-end 3D visualization combined with artificial-intelligence-enriched simulations for increasing climate resilience and for facilitating the decision-making process. The use cases driven value chain from *<<Chapter_VIS,style=basic%>>* is described in Chapter <<Chapter_VIS,droploc%>>. To close an important gap, a strong emphasis has been made to *<<Chapter_Communication,style=basic%>>* in Chapter <<Chapter_Communication,droploc%>> lining out the importance of consultation work to non-technical users to identify their requirements and optimize the information delivery use-case specific on demand.
Some of the value chain elements from raw data to visualization are illustrated by *<<Chapter_Use_Cases,style=basic%>>* in Chapter <<Chapter_Use_Cases,droploc%>>. And *<<Chapter_Lessons_Learned,style=basic%>>* (Chapter <<Chapter_Lessons_Learned,droploc%>>) showcase the pilot's work and include challenges with the value chain from raw data to climate information. The final chapter, chapter <<Chapter_Recommendations,droploc%>> *<<Chapter_Recommendations,style=basic%>>* describes future work.
